{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14666dc9",
   "metadata": {},
   "source": [
    "## Data[WeRateDogs] Wrangling Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f3a9d8",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "WeRateDogs is a Twitter account that rates people's dogs with a humoroius comment about the dog. We have an archived data that contains basic tweet data (tweet ID, timestamp, text, etc) for over 5,000 tweets as they stood on August 1, 2017.\n",
    "\n",
    "The purpose of the exercise was to gather and wrangle data from various sources specified for us. The data used for analysis was gathered from three different sources\n",
    "- Manual Download - Enhanced Twitter Archive\n",
    "- Programmatic Download - Image Predictions File\n",
    "- API - Additional Data from Twitter\n",
    "\n",
    "The wrangling efforts followed the iterative approach of the three steps in Data Wrangling, Gather -> Assess -> Clean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6eaa97",
   "metadata": {},
   "source": [
    "### Gathering\n",
    "\n",
    "**Manual Download - Enhanced Twitter Archive**\n",
    "\n",
    "This was the easiest dataset to acquire because it involved a direct download of the provided CSV file and importing into the project environment on my local machine.\n",
    " \n",
    "**Programmatic Download - Image Predictions File**\n",
    "\n",
    "With the help of python's requests library and the provided url, I programmatically downloaded the dataset and saved it into my project environment.\n",
    "\n",
    "**API - Additional Data from Twitter**\n",
    "\n",
    "This was the most tedious to acquire of all three datasets. I used a library called `tweepy`, which allows you to easily work with Twitter's API in python. The challenge was that, to use this library, you need to setup a Twitter's developer's account, which I did and had to wait for 48hours before it was finally approved. Upon being granted access, I created a project and had all credentials needed to use the library. I used the library to programmatically fetch the details I wanted via API and saved them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cae228",
   "metadata": {},
   "source": [
    "### Assessing\n",
    "\n",
    "Both visual and programmatic assessment was done on the three datasets. This assessment helped identify a number of Data Quality and Data Tidiness issues, which were properly documented with regards to the dataset it was identified in. The four Data Quality dimensions (Completeness, Consistency, Accuracy, Validity) helped in identifying quality issues, which was documented accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfa50e3",
   "metadata": {},
   "source": [
    "### Cleaning\n",
    "\n",
    "Proceeding from our detailed documentation of the Quality and Tidiness issues I found during out assessment, I worked on tackling each issue individually by following the steps involved for Data Cleaning, Define -> Code -> Test. After handling all defined issues, I was left with a master dataset, which I stored so would be further used for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dc0802",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:io] *",
   "language": "python",
   "name": "conda-env-io-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
